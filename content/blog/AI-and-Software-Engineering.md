+++
title = "AI and Software Engineering: Transformation, Not Replacement"
description = "Exploring how AI can help in software engineering"
date = 2024-10-10
draft = false

[taxonomies]
tags = ["Fintech", "Opinion", "AI"]

[extra]
toc = false
thumbnail = "/images/ChatGPT.jpg"
+++

{{img(src="/images/ChatGPT.jpg" alt="Ferris the Rustacean")}}

AI will replace software engineers, and we should start doing something else. At least, that is the current trend in quoting AI hypsters. Recently, even the NVIDIA CEO [said this](https://techwireasia.com/2024/03/nvidias-ceo-jensen-huang-ai-will-take-over-coding-making-learning-optional/). But in the end, he was more nuanced. He agrees that you still need foundational coding principles to make the code pairing with AI successful.

Besides, you still need these coding principles to guide the result successfully. People are also horrible at providing instructions on what they want. The hardest struggle I had was trying to get the details of what needed to be built. This is face-to-face, and I'm quite sure someone sitting in front of the input box of their LLM won't fare any better.

There is an even more significant issue when you share data and ideas with your online-hosted LLM system. Who owns the rights? We all know these LLM models are trained on copyrighted data and getting [sued](https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf) over it. OpenAI is now [claiming](https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai) the great benefits of AI can only be reached using copyrighted data. Is your company okay with this kind of stance?

Let's look into running our LLM on a model in-house. This way, we can feed it confidential information. To a certain degree, you are right. But information has access rights defined. This means maybe building different LLM pipelines based on this to make sure confidential information is not shared between people who shouldn't have access to it.

I am not claiming you should not use AI. But when implementing it in your company, be thoughtful about it. I am working in fintech, which is a heavily regulated domain, for example, regarding privacy. Before we blindly implement AI and LLMs, we need to work out a good plan. Maybe compliance will catch up and make your implementations illegal.

My recommendation is to explore the use of AI and LLMs. Start with a narrow band for experimentation to see where to extract value. Then, roll out thoughtfully, keeping in mind the confidentiality of data and who should be able to access it.

Here is some food for thought:

## The Evolving Role of Software Engineers

As AI tools become more integrated into software development workflows, the role of software engineers is shifting rather than disappearing. While generative AI can automate repetitive tasks like code generation and bug detection, it lacks the creativity and problem-solving skills inherent to human engineers. Software engineers will increasingly focus on higher-level tasks such as system architecture and user experience design—areas where human intuition and ethical considerations are paramount [1](https://amaris.com/insights/amaris-in-action/how-ai-is-redefining-software-engineering-for-a-digital-future/) [2](https://tech4th.com/how-ai-is-transforming-software-engineering/).

## The Necessity of Human Oversight

Even as AI systems become more sophisticated, they still require human oversight to ensure quality and alignment with project goals. The nuances of human language and context remain challenging for AI; thus, engineers must continue to provide direction and context that AI cannot inherently understand. This oversight is especially critical in sensitive fields like fintech, where compliance with regulations and ethical standards is non-negotiable [4](https://brainhub.eu/library/software-developer-age-of-ai).

## Intellectual Property Concerns

The question of intellectual property rights in AI-generated content remains unresolved. Companies must tread carefully when using AI tools trained on copyrighted materials [5](https://www.forbes.com/councils/forbestechcouncil/2023/04/24/how-ai-can-transform-the-software-engineering-process/). Understanding who owns the output generated by these systems is crucial for safeguarding proprietary information and avoiding legal pitfalls.

## Strategic Implementation of AI

When considering the implementation of AI tools within an organization, a strategic approach is essential. Companies should start small—experimenting with specific applications before scaling up [6](https://www.forbes.com/councils/forbestechcouncil/2024/06/0). This allows organizations to measure effectiveness while ensuring that data confidentiality is maintained.

In conclusion, while AI will undoubtedly change the landscape of software engineering, it does not signify an end for human engineers but rather a transformation of their roles. By embracing this shift thoughtfully and strategically, companies can leverage AI's capabilities while safeguarding their interests and maintaining ethical standards in technology development.
