+++
title = "Nobel Prize in physics for AI"
description = "My 2cents on this topic"
date = 2024-10-11
draft = false

[taxonomies]
tags = ["Opinion", "AI"]

[extra]
toc = false
+++

{{img(src="/images/nobel-prize.jpg" alt="Medal for AI nobel prize")}}

The [Nobel Prize in Physics was recently awarded](https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/) to pioneers in AI, sparking diverse reactions online. Some have celebrated it as a historic step, while others question whether AI even belongs in the realm of physics. This debate touches on the boundaries between scientific disciplines and how foundational research is evolving.

<!-- more -->

As someone passionate about philosophy, I find this discussion thought-provoking. Philosophy grapples with foundational questions—what exists, what we know, and how we ought to live—while physics delves into the mysteries of the universe, from subatomic particles to galaxies. Together, these fields share a history of exploring existence, each contributing to the other over centuries.

At the heart of both is a commitment to clear, rigorous thinking applied to fundamental questions. They challenge accepted wisdom and seek a deeper understanding of reality in the broadest terms—often converging in a shared pursuit of understanding "[everything](https://en.wikipedia.org/wiki/Theory_of_everything)."

Recently, I’ve sounded critical of AI, but my reservations aren’t about the technology itself. Instead, they stem from the opportunists creating an AI bubble that could harm the field in the long run. I fully support genuine AI advancements; however, this speculative hype risks inflated expectations that may eventually lead to disillusionment.

Moreover, I’m skeptical of current developments leading us to true Artificial General Intelligence (AGI). Large Language Models (LLMs), at their core, are complex matrix multiplications. While they may exhibit logical reasoning to an extent, can they truly create something new?

Take the case of Indian mathematician Ramanujan, who devised [complex formulas](https://en.wikipedia.org/wiki/Ramanujan%27s_sum) he claimed were inspired by a goddess in his dreams. These formulas, devoid of initial proofs, were later validated through rigorous logic by other mathematicians. This raises fascinating questions: where did such creativity originate? How did Ramanujan’s mind conjure these revolutionary ideas beyond logical deduction? Physics may explain his neurons and electrons, but it doesn’t quite capture how they spark this level of originality. It’s a reminder that the whole can indeed be greater than the sum of its parts—a complexity that computation alone cannot mimic.

So yes, I believe AI pioneers deserve the Nobel Prize, as AI’s goals align with physics in their quest to understand the “study of everything.” But reaching true AGI, with the capacity for creativity and inspiration, may be farther off than current AI advancements suggest.
